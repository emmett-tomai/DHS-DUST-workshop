{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade tensorflow  # % sign executes a shell command through jupyter notebook"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "# Downloading data file and save in compute file store\n",
        "url = \"https://raw.githubusercontent.com/emmett-tomai/DHS-DUST-workshop/main/data/penguins.csv\"\n",
        "local_file_path = \"penguins.csv\"\n",
        "urllib.request.urlretrieve(url, local_file_path)\n",
        "\n",
        "# Read the data into a Pandas DataFrame\n",
        "\n",
        "\n",
        "# Get rid of incomplete lines and show the first 5 rows\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691856487508
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem Data Definition\n",
        "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
        "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
        "label = 'Species'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691856489080
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas DataFrames and Series\n",
        "# https://pandas.pydata.org/docs/user_guide/10min.html\n",
        "\n",
        "\n",
        "\n",
        "# Deep Learning models work best when features are on similar scales\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691856490402
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorflow ANN library and easy-to-use Keras tools\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Set random seed for reproducability\n",
        "tensorflow.random.set_seed(8)\n",
        "\n",
        "print(\"Libraries imported.\")\n",
        "print('TensorFlow version:',tensorflow.__version__)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691856493729
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Extract features as an array of arrays (tensorflow uses high-performance numpy arrays)\n",
        "\n",
        "\n",
        "# Convert input values to float32 for network calculations\n",
        "\n",
        "\n",
        "# Set data types for categorical labels to \"one-hot\"\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691856495350
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create neural network\n",
        "\n",
        "# Fully-connected \"dense\" layers\n",
        "#  width, input dimentions, activation\n",
        "#  relu and softmax (probabilities)\n",
        "\n",
        "hl = 4 # Number of hidden layer nodes\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "print(model.summary())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691856521751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "# Optimizer and learning rate\n",
        "learning_rate = 0.001\n",
        "opt = optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Loss function (minimize)\n",
        "#  output: probability of each category being correct\n",
        "#  cross-entroy: sum of error between predicted and actual probabilities\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "#  train on full data set each epoch (and repeat)\n",
        "#  batch samples together for parameter updates (more efficient, stable)\n",
        "\n",
        "num_epochs = 10\n",
        "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evalutaion (WAIT ON THIS PART)\n",
        "\n",
        "# load testing set\n",
        "url = \"https://raw.githubusercontent.com/emmett-tomai/DHS-DUST-workshop/main/data/penguins_test.csv\"\n",
        "local_file_path = \"penguins_test.csv\"\n",
        "urllib.request.urlretrieve(url, local_file_path)\n",
        "\n",
        "# read the data into a Pandas DataFrame\n",
        "testdf = pd.read_csv(local_file_path).dropna()\n",
        "\n",
        "# pre-process (same as training data)\n",
        "\n",
        "\n",
        "# get predictions from model (inference)\n",
        "\n",
        "\n",
        "# take the highest probability answer for each test sample\n",
        "\n",
        "\n",
        "# calculate accuracy (number right / total predictions)\n",
        "\n",
        "\n",
        "\n",
        "print(acc)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691856762021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting (WAIT ON THIS PART)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "# plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "# plt.colorbar()\n",
        "# tick_marks = np.arange(len(penguin_classes))\n",
        "# plt.xticks(tick_marks, penguin_classes, rotation=85)\n",
        "# plt.yticks(tick_marks, penguin_classes)\n",
        "# plt.xlabel(\"Predicted Species\")\n",
        "# plt.ylabel(\"Actual Species\")\n",
        "# plt.show()\n",
        "\n",
        "# %matplotlib inline\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# epoch_nums = range(1,num_epochs+1)\n",
        "# training_loss = history.history[\"loss\"]\n",
        "# validation_loss = history.history[\"val_loss\"]\n",
        "# plt.plot(epoch_nums, training_loss)\n",
        "# plt.plot(epoch_nums, validation_loss)\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('loss')\n",
        "# plt.legend(['training', 'validation'], loc='upper right')\n",
        "# plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}